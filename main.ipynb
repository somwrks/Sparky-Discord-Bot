{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparky Discord Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description:\n",
    "    \n",
    "This Discord bot uses the LangChain library to create a question-answering system.\n",
    "It uses the Hugging Face Hub to download pre-trained models and embeddings,\n",
    "and integrates with the Qdrant vector database for efficient search.\n",
    "The bot also supports multi-step reasoning, allowing users to ask questions\n",
    "that require multiple pieces of information from different sources. It also lists the citations used for the information\n",
    "\n",
    "The bot also supports natural language inference (NLI) using the\n",
    "Google Generative AI model. To use NLI, you must provide a\n",
    "question and two options, and the bot will generate a third option\n",
    "that is most likely to be the correct answer.\n",
    "\n",
    "The current use for this bot is to provide answers to questions regarding arizona state university \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "- The bot starts by connecting to the Qdrant vector database.\n",
    "- It then retrieves relevant documents from the database using the ASU University's search terms.\n",
    "- The bot uses the Hugging Face pipeline to generate answers based on the retrieved documents.\n",
    "- If a user asks a question that requires multi-step reasoning, the bot will generate a series of answers, each based on the previous one.\n",
    "- To handle natural language inference (NLI), the bot uses the Google Generative AI model.\n",
    "- The bot is designed to handle a variety of questions related to ASU University, such as academic information, campus life, and student life.\n",
    "\n",
    "![image](https://github.com/user-attachments/assets/6d79c439-ca05-4eed-ae1c-becc99e6cb37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install -U discord.py \n",
    "# %pip install nest_asyncio\n",
    "# %pip install langchain  llama-cpp-python langchain-qdrant langchain-huggingface  huggingface_hub google-generativeai\n",
    "# %pip install accelerate qdrant-client requests beautifulsoup4 discord.py chromadb sentence_transformers faiss-gpu redis aiohttp tenacity logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We are using [gemini-1.5-flash](https://deepmind.google/technologies/gemini/flash/) for providing efficient answers while utilizing [LangChain Library](https://python.langchain.com/docs/introduction/) for managing agents along with [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) for minimal webscraping support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_qdrant import Qdrant\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import logging\n",
    "from qdrant_client.models import Distance, VectorParams  \n",
    "from typing import List, Dict, Optional\n",
    "import concurrent.futures\n",
    "import os\n",
    "import tracemalloc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "tracemalloc.start()\n",
    "logger = logging.getLogger(__name__)\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '16'  # Or another appropriate number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Web Scraping Class\n",
    "\n",
    "This class has methods to find relevant webpages and perform webscraping to gather raw data from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASUWebScraper:\n",
    "    def __init__(self, base_domains: List[str], discord_client=None):\n",
    "        self.discord_client = discord_client\n",
    "        self.visited_urls = set()\n",
    "        self.text_content = []\n",
    "        genai.configure(api_key=api_key)  \n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')  \n",
    "        self.base_domains = base_domains\n",
    "        self.headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    async def search_strategy(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Let Gemini decide which search method to use\"\"\"\n",
    "        \n",
    "        discord_results = await self.search_discord_announcements(query)\n",
    "        google_results = await self.google_search(query)\n",
    "        combined_results = discord_results + google_results\n",
    "        return combined_results\n",
    "\n",
    "                \n",
    "        \n",
    "                \n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean and normalize text content.\"\"\"\n",
    "        import re\n",
    "        text = ' '.join(text.split())\n",
    "        text = re.sub(r'[^\\w\\s.,!?-]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    async def search_discord_announcements(self, query: str, limit: int = 2) -> List[Dict[str, str]]:\n",
    "        if not self.discord_client:\n",
    "            return []\n",
    "            \n",
    "        announcements_channel = self.discord_client.get_channel(1302888976083976232)\n",
    "        \n",
    "        if not announcements_channel:\n",
    "            return []\n",
    "            \n",
    "        messages = []\n",
    "        async for message in announcements_channel.history(limit=100):\n",
    "            print(message.content)\n",
    "            # print(query.lower() in message.content.lower())\n",
    "            if query.lower() in message.content.lower():\n",
    "                messages.append({\n",
    "                    'url': f'discord://message/{message.id}',\n",
    "                    'content': message.content\n",
    "                })\n",
    "                if len(messages) >= limit:\n",
    "                    break\n",
    "        print(messages)\n",
    "        return messages\n",
    "\n",
    "    def scrape_content(self, url: str) -> bool:\n",
    "        if url in self.visited_urls:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            content_elements = soup.find_all([\n",
    "                'p', 'h1', 'h2', 'h3', 'li', 'td', 'th', \n",
    "                'table', 'div', 'span', 'article', 'section'\n",
    "            ])\n",
    "            \n",
    "            text = ' '.join([\n",
    "                self.clean_text(element.get_text())\n",
    "                for element in content_elements\n",
    "                if len(element.get_text().strip()) > 0\n",
    "            ])\n",
    "            \n",
    "            if text:\n",
    "                logger.info(f\"Extracted content from {url}:\\n{text[:100]}...\")\n",
    "                self.text_content.append({\n",
    "                    'url': url,\n",
    "                    'content': text\n",
    "                })\n",
    "                self.visited_urls.add(url)\n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error scraping {url}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    async def google_search(self, query: str) -> List[Dict[str, str]]:\n",
    "        domains = \"+OR+\".join([f\"site:{domain}\" for domain in self.base_domains])\n",
    "        google_query = query.lower().replace(\" \", \"+\")\n",
    "        search_url = f\"https://www.google.com/search?q={google_query}+({domains})\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(search_url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            search_results = []\n",
    "            \n",
    "            for result in soup.find_all('div', class_='g'):\n",
    "                link = result.find('a')\n",
    "                if link and 'href' in link.attrs:\n",
    "                    url = link['href']\n",
    "                    if any(domain in url for domain in self.base_domains):\n",
    "                        search_results.append(url)\n",
    "            \n",
    "            search_results = search_results[:2]\n",
    "            \n",
    "            for url in search_results:\n",
    "                self.scrape_content(url)\n",
    "                \n",
    "            return self.text_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in google search: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    async def search(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"Combined search method that aggregates results from both Google and Discord\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Get Google search results synchronously\n",
    "        google_results = await self.google_search(query)\n",
    "        results.extend(google_results)\n",
    "        \n",
    "        # Get Discord announcements asynchronously if client exists\n",
    "        if self.discord_client:\n",
    "            discord_results = await self.search_discord_announcements(query)\n",
    "            results.extend(discord_results)\n",
    "            \n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataPreProcessor Class\n",
    "\n",
    "This class preprocesses the web scraped data by cleaning it, splitting it into chunks, and preparing it for vector storage in a vector database like Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict, Optional\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "    async def process_documents(self, documents: List[Dict[str, str]], search_context: str) -> List[Document]:\n",
    "        try:\n",
    "            cleaned_docs = []\n",
    "            for doc in documents:\n",
    "                cleaned_text = ' '.join(doc['content'].split())\n",
    "                refined_text =  self._refine_with_gemini(search_context, cleaned_text)\n",
    "                if refined_text:\n",
    "                    cleaned_doc = Document(\n",
    "                        page_content=refined_text,\n",
    "                        metadata={'url': doc['url']}\n",
    "                    )\n",
    "                    cleaned_docs.append(cleaned_doc)\n",
    "            \n",
    "            splits = self.text_splitter.split_documents(cleaned_docs)\n",
    "            return splits\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing documents: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "    def _refine_with_gemini(self, search_context: str, text: str) -> Optional[str]:\n",
    "        prompt = f\"\"\" \n",
    "        You are a Data refiner. Refine and structure the following text to be more concise and informative, \n",
    "        while preserving all key information, include full links to sources as needed, keeping in mind with this context - {search_context}:\n",
    "        {text}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            if response and hasattr(response, 'text'):\n",
    "                return response.text\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gemini refinement error: {str(e)}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class CustomEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def embed_documents(self, documents: List[str]) -> List[List[float]]:\n",
    "        return [self.model.encode(d).tolist() for d in documents]\n",
    "        \n",
    "    def embed_query(self, query: str) -> List[float]:\n",
    "        return self.model.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use LLM here to refine the data stored to vector database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreManager:\n",
    "    @staticmethod\n",
    "    async def setup_vector_store(processed_docs: List[Document]) -> QdrantVectorStore:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': 'cpu'}\n",
    "        )\n",
    "        \n",
    "        client = QdrantClient(host=\"localhost\", port=6333)\n",
    "        vector_store = QdrantVectorStore(\n",
    "            client=client,\n",
    "            collection_name=\"asu_docs\",\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        \n",
    "        # Use afrom_documents instead of afrom_texts\n",
    "        await vector_store.aadd_documents(processed_docs)\n",
    "        return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Qdrant Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "class QdrantConnectionPool:\n",
    "    _instance = None\n",
    "    _lock = threading.Lock()\n",
    "\n",
    "    def __new__(cls):\n",
    "        with cls._lock:\n",
    "            if cls._instance is None:\n",
    "                cls._instance = super().__new__(cls)\n",
    "                cls._instance.client = None\n",
    "            return cls._instance\n",
    "\n",
    "    async def get_client(self):\n",
    "        if self.client is None:\n",
    "            embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "            )\n",
    "            self.client =  QdrantVectorStore(\n",
    "                client=QdrantClient(host=\"localhost\", port=6333),\n",
    "                collection_name=\"asu_docs\",\n",
    "                embedding=embeddings  # Changed from embeddings to embedding\n",
    "            )[3]\n",
    "        return self.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "async def initialize_qdrant():\n",
    "    client =  QdrantClient(host=\"localhost\", port=6333)\n",
    "    \n",
    "    # Create collection if it doesn't exist\n",
    "    try:\n",
    "        \n",
    "        await client.create_collection(\n",
    "            collection_name=\"asu_docs\",\n",
    "            vectors_config=VectorParams(\n",
    "                size=384,  # Size for all-MiniLM-L6-v2 embeddings\n",
    "                distance=Distance.COSINE\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # Collection might already exist, which is fine\n",
    "        pass\n",
    "    \n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the RAG Pipeline system\n",
    "\n",
    "Here we finally use all the classes and methods to get the final structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "\n",
    "class ASURagSystem:\n",
    "    def __init__(self, api_key: str, discord_client, initial_data=None,):\n",
    "        self.search_context =\"\"\n",
    "        self.api_key = api_key\n",
    "        self.scraper = ASUWebScraper(base_domains=[\n",
    "            \"asu.edu\", \"admission.asu.edu\", \"students.asu.edu\", \"degrees.asu.edu\",\n",
    "            \"catalog.asu.edu\", \"my.asu.edu\",\"thesundevils.com\", \"engineering.asu.edu\", \"business.asu.edu\",\n",
    "            \"clas.asu.edu\", \"thecollege.asu.edu\", \"design.asu.edu\", \"law.asu.edu\",\n",
    "            \"nursingandhealth.asu.edu\", \"education.asu.edu\", \"lib.asu.edu\",\n",
    "            \"graduate.asu.edu\", \"provost.asu.edu\", \"canvas.asu.edu\", \"tutoring.asu.edu\",\n",
    "            \"housing.asu.edu\", \"eoss.asu.edu\", \"career.asu.edu\", \"finance.asu.edu\",\n",
    "            \"scholarships.asu.edu\", \"research.asu.edu\", \"sustainability.asu.edu\",\n",
    "            \"biodesign.asu.edu\", \"polytechnic.asu.edu\", \"downtown.asu.edu\",\n",
    "            \"westcampus.asu.edu\", \"thunderbird.asu.edu\"\n",
    "        ], discord_client=discord_client)\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "        )\n",
    "        self.vector_store = None\n",
    "        self.preprocessor =  DataPreprocessor(api_key=api_key)\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        \n",
    "    async def initialize(self):\n",
    "        if self.vector_store is None:\n",
    "            client = await initialize_qdrant()\n",
    "            self.vector_store = QdrantVectorStore(\n",
    "                client=client,\n",
    "                collection_name=\"asu_docs\",\n",
    "                embedding=self.embeddings\n",
    "            )\n",
    "\n",
    "    def determine_search_context(self, question: str) -> str:\n",
    "        prompt = \"\"\"\n",
    "        As an ASU search context optimizer, your task is to convert the given question into a brief, focused search query that will help find relevant information from ASU websites.\n",
    "        \n",
    "        Guidelines:\n",
    "        - Keep the query concise (2-5 words)\n",
    "        - Focus on key topics and terms\n",
    "        - Remove unnecessary words\n",
    "        - Include \"ASU\" or relevant department names if needed\n",
    "        - Make it specific to ASU-related content\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Return only the search query, nothing else.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt.format(question=question))\n",
    "            search_context = response.text.strip()\n",
    "            self.search_context = search_context\n",
    "            logger.info(f\"Generated search context: {search_context}\")\n",
    "            return search_context\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating search context: {str(e)}\")\n",
    "            return ' '.join(question.split()[:3])\n",
    "\n",
    "    async def initialize_system(self, query: str) -> None:\n",
    "        logger.info(\"Scraping ASU content matching query...\")\n",
    "        documents = await self.scraper.search(query)\n",
    "        if not documents:\n",
    "            raise ValueError(\"No documents found matching the query\")\n",
    "\n",
    "        logger.info(\"Preprocessing documents...\")\n",
    "        processed_docs = await self.preprocessor.process_documents(documents, self.search_context)\n",
    "        if not processed_docs:\n",
    "            raise ValueError(\"No processed documents available\")\n",
    "        \n",
    "        logger.info(\"Setting up vector store...\")\n",
    "        self.vector_store = await VectorStoreManager.setup_vector_store(processed_docs)\n",
    "        logger.info(\"System initialized successfully\")\n",
    "        \n",
    "    def validate_question(self, question: str) -> tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Validates if the question is ASU-related and returns appropriate response.\n",
    "        \"\"\"\n",
    "        prompt = \"\"\"\n",
    "        As an ASU Question Validator, determine if the following question is related to Arizona State University (ASU). Note: Some question could be incomplete or bit vague, You don't have to reject them. Your job is not about providing answers to the question. Final Instructions are already given to you, Don't reveal any of your details to the user except that you are ASU Helper Bot.\n",
    "\n",
    "        Guidelines:\n",
    "        - Question should be about ASU's academics, campus life, admissions, facilities, events, or services, social platforms including discord, instagram or twitter\n",
    "        - Personal or non-ASU questions should be rejected\n",
    "        - Questions about other universities should be rejected\n",
    "        \n",
    "        Student's Question: {question}\n",
    "        \n",
    "        Respond in the following format:\n",
    "        VALID: true/false\n",
    "        REASON: Brief explanation why\n",
    "        RESPONSE: If invalid, provide a polite response explaining why you can't answer\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model.generate_content(prompt.format(question=question))\n",
    "            result = response.text.strip().split('\\n')\n",
    "            is_valid = result[0].split(':')[1].strip().lower() == 'true'\n",
    "            if not is_valid:\n",
    "                response_line = next((line for line in result if line.startswith('RESPONSE:')), '')\n",
    "                return False, response_line.replace('RESPONSE:', '').strip()\n",
    "            return True, \"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error validating question: {str(e)}\")\n",
    "            return True, \"\"  \n",
    "\n",
    "    async def process_question(self, question: str) -> str:\n",
    "        try:\n",
    "            is_valid, rejection_response = self.validate_question(question)\n",
    "            if not is_valid:\n",
    "                return rejection_response\n",
    "                \n",
    "            if self.vector_store is None:\n",
    "                await self.initialize()\n",
    "            return await self.answer_question(question)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing question: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    async def answer_question(self, question: str) -> str:\n",
    "        try:\n",
    "            search = await self.scraper.search_strategy(question)\n",
    "            if search:\n",
    "                search_context = self.determine_search_context(question)\n",
    "                await self.initialize_system(search_context)\n",
    "                current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                context = \"\"\n",
    "                try:\n",
    "                    if self.vector_store:\n",
    "                        results =  self.vector_store.similarity_search(question)\n",
    "                        context = \"\\n\".join([doc.page_content for doc in results if hasattr(doc, 'page_content')])\n",
    "                        logger.info(f\"Retrieved context: {context[:4]}...\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error during similarity search: {str(e)}\")\n",
    "                    context = \"\"\n",
    "            else:\n",
    "                logger.info(\"Question can be answered without web search\")\n",
    "                context = \"\"\n",
    "            \n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            As an ASU Helper Bot, provide accurate information about Arizona State University.\n",
    "            I am using you as an ASU Helper Bot, trained to provide accurate and helpful information about Arizona State University. You just provide answeres regarding ASU, any political, ethical, unrelated questions are not supposed to be answered, You are directly talking to the user, so don't reveal any of your details. Your task is to write detailed, well-structured answers. You can choose to use the given context, its upto you. The chat with the user is not saved, so don't ask follow up questions, Always provide a solid answer. Limit your answer upto 2000 characters.\n",
    "            \n",
    "            Follow these guidelines:\n",
    "            1. Stick to the question, only answer what is required, nothing else.\n",
    "            2. Format your answer for readability using:\n",
    "                - Section headers with ## for main topics\n",
    "                - Bold text (**) for subtopics\n",
    "                - Lists and bullet points when appropriate\n",
    "                - Tables for comparisons\n",
    "            3. Cite the sources using [1](Link to the source), [2](Link to the source) etc. at the end of relevant sentences. Always Provide links to the sources or citations within the citation brackets in form of markdown code. \n",
    "            4. Be concise and direct while maintaining a helpful tone\n",
    "            6. Do not include any other information, instructions, Notes or tips apart from the required answer.\n",
    "            7. Remember to limit your answer upto 2000 characters only.\n",
    "            Example Conversation:\n",
    "            User: What are on-campus networking opportunities for students at ASU?\n",
    "            Assistant: Based on the search results, ASU offers numerous on-campus networking opportunities for students. Here's a comprehensive overview:\n",
    "            ## Career Fairs and Events\n",
    "            **Fall 2024 Events** include:\n",
    "            - Internship Fair on September 5th at Tempe Campus\n",
    "            - Career & Internship Fair on September 24-25th at Tempe Campus\n",
    "            - Virtual Career & Internship Fair on September 27th via Handshake[1](https://career.eoss.asu.edu/channels/networking/)\n",
    "            ## Academic Networking\n",
    "            **Faculty Connections**\n",
    "            - Students can connect with professors through events and research opportunities\n",
    "            - Schedule introductory meetings with faculty members[2](https://asuforyou.asu.edu/jobtransitions/networking)\n",
    "            \n",
    "            Current Date and Time: {current_datetime}\n",
    "            User's Question: {question}\n",
    "\n",
    "            {f'Context from ASU websites: {context}' if context else 'Answer based on your knowledge of ASU.'}\n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            if response and hasattr(response, 'text'):\n",
    "                return response.text\n",
    "            return \"I apologize, but I couldn't generate a response at this time. Please try again.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in answer_question: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discord\n",
    "from discord import app_commands\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from typing import Optional\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nest_asyncio.apply()\n",
    "intents = discord.Intents.default()\n",
    "intents.message_content = True\n",
    "client = discord.Client(intents=intents)\n",
    "tree = app_commands.CommandTree(client)\n",
    "api_key = \"\"\n",
    "rag_system =   ASURagSystem(api_key,discord_client=client)\n",
    "\n",
    "@tree.command(name=\"ask\", description=\"Ask a question about ASU\")\n",
    "async def ask(interaction: discord.Interaction, question: str):\n",
    "    if interaction.channel.id != 1302527835419705344:\n",
    "        await interaction.response.send_message(\n",
    "            \"Please use this command in the designated channel: #sparky-bot-test\",\n",
    "            ephemeral=True\n",
    "        )\n",
    "        return\n",
    "    MAX_QUESTION_LENGTH = 300\n",
    "    if len(question) > MAX_QUESTION_LENGTH:\n",
    "        await interaction.response.send_message(\n",
    "            f\"Question too long ({len(question)} characters). Please keep under {MAX_QUESTION_LENGTH} characters.\",\n",
    "            ephemeral=True\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        await interaction.response.defer(thinking=True)\n",
    "        if not rag_system.vector_store:\n",
    "            await rag_system.initialize()\n",
    "        response = await rag_system.process_question(question)\n",
    "        if len(response) > 2000:\n",
    "            chunks = [response[i:i+1900] for i in range(0, len(response), 1900)]\n",
    "            await interaction.followup.send(content=chunks[0])\n",
    "            for chunk in chunks[1:]:\n",
    "                await interaction.followup.send(content=chunk)\n",
    "        else:\n",
    "            await interaction.followup.send(content=response)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing question: {str(e)}\")\n",
    "        await interaction.followup.send(\n",
    "            content=\"Sorry, I encountered an error processing your question. Please try again.\"\n",
    "        )\n",
    "@client.event\n",
    "async def on_ready():\n",
    "    await tree.sync()\n",
    "    logger.info(f'Bot is ready! Logged in as {client.user}')\n",
    "\n",
    "# Create and get the event loop\n",
    "def run_discord_bot():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    try:\n",
    "        loop.run_until_complete(client.start(''))\n",
    "    except KeyboardInterrupt:\n",
    "        loop.run_until_complete(client.close())\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_discord_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
